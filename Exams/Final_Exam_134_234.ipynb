{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Final Exam\n",
    "**PSTAT 134/234 (Spring 2024)  \n",
    "\n",
    "\n",
    "\n",
    "## Data description: Fraudulent transactions\n",
    "\n",
    "A credit card company wants to know whether a set of variables $x_1, \\ldots, x_p$ have an impact on the probability of a given transaction being fraudulent. To understand the relationship between these predictor variables and the probability of a transaction being fraudulent, the company can perform logistic regression where the response is defined as: \n",
    "\n",
    "$$ \n",
    "y = \\begin{cases}\n",
    "    1, & \\text{if transaction is fraudulent.}  \\\\\n",
    "    0, & \\text{otherwise. } \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Read Data into Python\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "manual: true\n",
    "points: 10\n",
    "-->\n",
    "\n",
    "1. Unzip folder `DataFinalExam` in your working directory.\n",
    "2. Use regular expressions to filter data sets that match the conditions:\n",
    "    * Starting with pattern 'Data'\n",
    "    * From years: 2020, 2021, 2022\n",
    "    * From months: January, February, March and April\n",
    "3. Concatenate all files in a single data frame\n",
    "4. Set Y to be column 'Y' and X as the remaining columns of the merged data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '...'  # Replace with your folder path\n",
    "\n",
    "# Define the regular expression pattern for the desired filenames\n",
    "pattern = r'...'  ##Starting by 'Data', only months: Jan-April, Only Years 2020, 2021 and 2022\n",
    "\n",
    "\n",
    "# Initialize an empty list to store the data frames\n",
    "dfs = []\n",
    "\n",
    "# Iterate over the files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file matches the desired pattern\n",
    "    if re.match(pattern, file_name):\n",
    "        # Read the CSV file and append the data frame to the list\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "        print(file_name)\n",
    "\n",
    "# Concatenate the data frames into a single data frame\n",
    "merged_df = ...\n",
    "\n",
    "X = ...\n",
    "Y = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Question 2\n",
    "\n",
    "In this problem, we use convex optimization to train a logistic regression model with regularization. We are given data $\\left(x_i, y_i\\right), i=1, \\ldots, n$. The $x_i \\in \\mathbf{R}^p$ are feature vectors, while the $y_i \\in\\{0,1\\}$ are associated boolean classes.\n",
    "\n",
    "The goal is to construct a linear classifier $\\hat{y}=\\mathbb{1}\\left[x^T \\beta>0\\right]$, which is 1 when $x^T \\beta$ is positive and 0 otherwise. We model the posterior probabilities of the classes given the data linearly, with\n",
    "$$\n",
    "\\log \\frac{\\operatorname{Pr}(Y=1 \\mid X=x)}{\\operatorname{Pr}(Y=0 \\mid X=x)}=x^T \\beta\n",
    "$$\n",
    "This implies that\n",
    "$$\n",
    "\\operatorname{Pr}(Y=1 \\mid X=x)=\\frac{\\exp \\left(x^T \\beta\\right)}{1+\\exp \\left(x^T \\beta\\right)}, \\quad \\operatorname{Pr}(Y=0 \\mid X=x)=\\frac{1}{1+\\exp \\left(x^T \\beta\\right)} .\n",
    "$$\n",
    "We fit $\\beta$ by maximizing the log-likelihood of the data:\n",
    "$$\n",
    "\\ell(\\beta)=\\sum_{i=1}^n y_i x_i^T \\beta-\\log \\left(1+\\exp \\left(x_i^T \\beta\\right)\\right)\n",
    "$$\n",
    "\n",
    "Because $\\ell$ is a concave function of $\\beta$, this is a convex optimization problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2a:\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "manual: true\n",
    "points: 50\n",
    "-->\n",
    "1. Use gradient descent to create function `Update_Beta` that uses the data as input, to obtain the optimal value of $\\beta$.\n",
    "     - At each iteration of your algorithm the function should keep track of the maximum update, $Max_{update} = \\|\\beta_{new} - \\beta\\|_{\\infty} $ and the mean absolute error defined as, $error= \\sum_{i=1}^n \\frac{|y_i - \\hat{y_i}|}{n}$\n",
    "2. Use your function to estimate $\\beta$.\n",
    "\n",
    "*Hint*: Use the fact that maximizig the concave function $f(x)$ is equivalent to minimizing the convex function $-f(x)$.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill-in ...\n",
    "def Update_Beta(X, y, alpha=0.01, max_iteration=100):\n",
    "   \n",
    "    ... \n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2b:\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "manual: true\n",
    "points: 20\n",
    "-->\n",
    "\n",
    "Use diagnostic plots to assess the convergence of your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2c (PSTAT 234)\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "manual: true\n",
    "points: 30\n",
    "-->\n",
    "\n",
    "Suppose we incorporate a regularization term $\\lambda\\|\\beta\\|_1$ with $\\lambda>0$, so that the objective function to be maximized is:\n",
    "$$\n",
    "\\ell(\\beta)=\\sum_{i=1}^n y_i x_i^T \\beta-\\log \\left(1+\\exp \\left(x_i^T \\beta\\right)\\right)-\\lambda\\|\\beta\\|_1\n",
    "$$\n",
    "\n",
    "With $\\|\\beta\\|_1 = \\sum_{j=1}^p |\\beta_j|$.\n",
    "\n",
    "1. By using the library `cvxpy`, create the function `Update_Beta_reg` that takes the data and the value of $\\lambda$ as inputs to obtain the optimal value of $\\beta$. \n",
    "2. Run a loop that iterates over different values of $\\lambda$ (in between 0.01 and 1), and uses the function that you created (`Update_Beta_reg`) to obtain several solutions for $\\beta$.\n",
    "3. What value of $\\lambda$ would you choose based on the average absolute error?\n",
    "4. How these resultes compare to part 2a?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill-in ...\n",
    "def Update_Beta_reg(X, y, lambda_val):\n",
    "    \n",
    "   \n",
    "    ... \n",
    "    return ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Checklist\n",
    "1. Save file to confirm all changes are on disk\n",
    "2. Run *Kernel > Restart & Run All* to execute all code from top to bottom\n",
    "3. Save file again to write any new output to disk\n",
    "4. Select *File > Save and export Notebook as/ > HTML*.\n",
    "5. Open in Google Chrome and print to PDF.\n",
    "6. Submit to Gradescope\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
